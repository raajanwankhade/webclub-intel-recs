{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYkH5y3Qzckz"
      },
      "source": [
        "# Translation Models\n",
        "\n",
        "\n",
        "Machine translation is a pivotal field within natural language processing (NLP) that focuses on automating the conversion of text or speech from one language to another. It relies on sophisticated models and techniques to accomplish this challenging task effectively. One of the cornerstone methods in machine translation is the sequence-to-sequence (seq2seq) model, which employs deep neural networks to encode input text and then decode it into the target language. This technique has revolutionized translation tasks by learning to capture complex linguistic nuances and contextual information. Additionally, other models like Transformer-based models, including the famous BERT and GPT-3, have also made significant strides in translation, leveraging attention mechanisms to excel in various language pairs and domains. The choice of model depends on specific translation requirements, language pairs, and the quality of available training data. In this Colab file, we havee given a basic demo on how tto use the dataset and work on a simple seq2seq moel usig RNN.Your task will be to improve the model to the maximum you can ,make prediction on the test dataset given and write a code to generate the BLEU score of you prediction compared to original.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nS1d9rgev8J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional,LSTM, Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbtD0ux5ew7d"
      },
      "outputs": [],
      "source": [
        "##Loading and processing data\n",
        "eng_fr = pd.read_csv(\"nlp_intel_train.csv\")\n",
        "eng_fr_test = pd.read_csv(\"nlp_intel_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs9CABoPfty1"
      },
      "outputs": [],
      "source": [
        "eng_fr = eng_fr.dropna(axis=0, how=\"any\", subset=None, inplace=False)\n",
        "eng_fr_test = eng_fr_test.dropna(axis=0, how=\"any\", subset=None, inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cenL2y2df2p1"
      },
      "outputs": [],
      "source": [
        "##Tokenizer and padding\n",
        "\n",
        "def tokenize(data):\n",
        "  t = Tokenizer()\n",
        "  t.fit_on_texts(data)\n",
        "  return t\n",
        "def training_sequences(tokenizer, m_length, data):\n",
        "    seq = tokenizer.texts_to_sequences(data)\n",
        "    seq = pad_sequences(seq, maxlen = m_length, padding='post')\n",
        "    return seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKK20PUMg4K3"
      },
      "outputs": [],
      "source": [
        "#Preprocessing by tokenization and padding\n",
        "#return processed data and tokenizer\n",
        "def preprocess(x, y):\n",
        "\n",
        "    x_tk = tokenize(x)\n",
        "    y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = training_sequences(x_tk,55,x)\n",
        "    preprocess_y = training_sequences(y_tk,55,y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWl-vgZziSeD"
      },
      "outputs": [],
      "source": [
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(eng_fr[\"en\"].tolist(), eng_fr[\"fr\"].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yU5F-7eii6N",
        "outputId": "d3198a74-8252-4cbf-c8c7-8eddaa4eba4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max English sentence length: 55\n",
            "Max French sentence length: 55\n",
            "English vocabulary size: 21789\n",
            "French vocabulary size: 27712\n"
          ]
        }
      ],
      "source": [
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP1THRqril3N"
      },
      "outputs": [],
      "source": [
        "#Final output funtion\n",
        "def logits_to_text(logits, tokenizer):\n",
        "\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ' '\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eoy5079ni0z3"
      },
      "outputs": [],
      "source": [
        "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Build the layers\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(french_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
        "    model.add(GRU(256, return_sequences=True))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dense(english_vocab_size, activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bRXEU8TjWNL",
        "outputId": "2f87dfe0-52c2-447d-f16d-ad3802a180db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preproc_french_sentences.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu1W91SAi1mv",
        "outputId": "ea17c58d-c933-413c-cd6a-c8a16ea78140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 55, 256)           7094528   \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 55, 256)           394752    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 55, 1024)          263168    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 55, 21790)         22334750  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30087198 (114.77 MB)\n",
            "Trainable params: 30087198 (114.77 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "225/225 [==============================] - 55s 234ms/step - loss: 2.8452 - accuracy: 0.6713 - val_loss: 2.4256 - val_accuracy: 0.6964\n",
            "Epoch 2/5\n",
            "225/225 [==============================] - 49s 215ms/step - loss: 2.4563 - accuracy: 0.6807 - val_loss: 2.4346 - val_accuracy: 0.6927\n",
            "Epoch 3/5\n",
            "225/225 [==============================] - 48s 214ms/step - loss: 2.2874 - accuracy: 0.6873 - val_loss: 2.3814 - val_accuracy: 0.6960\n",
            "Epoch 4/5\n",
            "225/225 [==============================] - 47s 211ms/step - loss: 2.1021 - accuracy: 0.6949 - val_loss: 2.4218 - val_accuracy: 0.6974\n",
            "Epoch 5/5\n",
            "225/225 [==============================] - 46s 206ms/step - loss: 1.9107 - accuracy: 0.7029 - val_loss: 2.4927 - val_accuracy: 0.6904\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dbf892d9ed0>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_x =pad_sequences(preproc_french_sentences, maxlen = 55, padding = 'post')\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
        "\n",
        "# Train\n",
        "model = bd_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_english_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(tmp_x, preproc_english_sentences, batch_size=64, epochs=5, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdY7DBVQksvf",
        "outputId": "baae766d-367e-4878-d9e2-1c3412fab594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction:\n",
            "1/1 [==============================] - 0s 330ms/step\n",
            "the club was is active and of the two the in of and 1997 the the of of the of of the amateur of of <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "The club was very active and they twice organized the annual conference of the Amateur Astronomy Federation of Quebec in 1990 and 1997.\n",
            "\n",
            "Original text:\n",
            "Le club est très actif et organise à deux occasions (en 1990 et 1997) le congrès annuel de la Fédération des Astronomes Amateurs du Québec.\n"
          ]
        }
      ],
      "source": [
        "i= 1\n",
        "\n",
        "\n",
        "print(\"Prediction:\")\n",
        "print(logits_to_text(model.predict(tmp_x[[i]])[0], english_tokenizer))\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(eng_fr[\"en\"].tolist()[i])\n",
        "print(\"\\nOriginal text:\")\n",
        "print(eng_fr[\"fr\"].tolist()[i])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
